# üå¶Ô∏è **Previs√£o Meteorol√≥gica ‚Äì Desafio T√©cnico Tecgraf / PUC-Rio**

### üë®‚Äçüíª **Autor: Thales Gabriel da Silva Fiscus**

Este reposit√≥rio cont√©m a solu√ß√£o do desafio t√©cnico de previs√£o meteorol√≥gica baseado em um hist√≥rico de **10 anos de dados hor√°rios**, com o objetivo de gerar previs√µes de **temperatura** e **chuva** para todas as horas do pr√≥ximo ano (‚âà **8760 horas**).

A solu√ß√£o inclui:

* ‚úîÔ∏è **An√°lise explorat√≥ria dos dados**
* ‚úîÔ∏è **Tratamento e normaliza√ß√£o das features**
* ‚úîÔ∏è **Prepara√ß√£o adequada da s√©rie temporal**
* ‚úîÔ∏è **Treinamento de dois modelos de machine learning (LightGBM)**
* ‚úîÔ∏è **Valida√ß√£o com Time Series Cross-Validation (TSCV)**
* ‚úîÔ∏è **Otimiza√ß√£o de hiperpar√¢metros com Random Search**
* ‚úîÔ∏è **Gera√ß√£o do arquivo final `PREVISAO.csv`**
* ‚úîÔ∏è **Documenta√ß√£o completa no Jupyter Notebook**

---

# üìÇ **Arquivos do Reposit√≥rio**

| Arquivo                   | Descri√ß√£o                                                 |
| ------------------------- | --------------------------------------------------------- |
| `HISTORICO.csv`           | Hist√≥rico de 10 anos de dados meteorol√≥gicos (fornecido). |
| `PREVISAO.csv`            | Arquivo final contendo a previs√£o hora a hora para 1 ano. |
| `notebook_previsao.ipynb` | Notebook completo com todos os passos do projeto.         |
| `README.md`               | Este documento.                                           |

---

# üß† **Vis√£o Geral da Solu√ß√£o**

### ‚úîÔ∏è **Modelagem Separada**

Foram criados dois modelos independentes, ambos utilizando LightGBM:

* **Modelo 1 ‚Äî Temperatura**
* **Modelo 2 ‚Äî Chuva**

Temperatura e chuva apresentam padr√µes temporais e comportamentos estat√≠sticos muito distintos, o que faz com que modelos separados entreguem resultados mais est√°veis e melhor ajustados √†s caracter√≠sticas de cada vari√°vel.

---

# üîç **Processo Metodol√≥gico**

O pipeline segue boas pr√°ticas consolidadas para s√©ries temporais.

---

## **1. Importa√ß√£o e Pr√©-processamento**

* Carregamento do arquivo `HISTORICO.csv`
* Convers√£o da coluna `time` para datetime
* Separa√ß√£o das vari√°veis-alvo
* Identifica√ß√£o das features

Essa etapa organiza os dados e garante que a estrutura temporal seja preservada antes do in√≠cio da modelagem.

```python
# === CARREGAMENTO DO HIST√ìRICO ===

df = pd.read_csv("HISTORICO.csv")

# Convertendo coluna time
df["time"] = pd.to_datetime(df["time"])

df.head()

# === SEPARA√á√ÉO DE FEATURES E TARGETS ===

target_temp = "temperature_2m (¬∞C)"
target_rain = "rain (mm)"

feature_cols = [c for c in df.columns if c not in ["time", target_temp, target_rain]]

X = df[feature_cols].copy()
y_temp = df[target_temp].copy()
y_rain = df[target_rain].copy()

X.head()
```

---

## **2. Normaliza√ß√£o**

* Uso do `StandardScaler`
* Normaliza√ß√£o aplicada apenas √†s features
* Targets permanecem na escala original

Essa normaliza√ß√£o melhora estabilidade num√©rica no treinamento e impede que vari√°veis muito maiores influenciem desproporcionalmente o modelo.

```python
# === NORMALIZA√á√ÉO DAS FEATURES ===

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)

X_scaled.head()
```

---

## **3. Divis√£o Temporal**

* 80% dos dados para treino
* 20% para teste final

Dentro do treino:

* 80% treino interno
* 20% valida√ß√£o interna

A divis√£o mant√©m a ordem cronol√≥gica para evitar vazamento de dados futuros, essencial em s√©ries temporais.

```python
# === SPLIT TEMPORAL (80% TREINO / 20% TESTE) ===

train_size = int(len(X_scaled) * 0.8)

X_train = X_scaled.iloc[:train_size]
X_test  = X_scaled.iloc[train_size:]

y_temp_train = y_temp.iloc[:train_size]
y_temp_test  = y_temp.iloc[train_size:]

y_rain_train = y_rain.iloc[:train_size]
y_rain_test  = y_rain.iloc[train_size:]


# === VALIDA√á√ÉO INTERNA (20% DO TREINO) ===

valid_size = int(len(X_train) * 0.2)

X_train_internal = X_train.iloc[:-valid_size]
X_valid          = X_train.iloc[-valid_size:]

y_temp_train_internal = y_temp_train.iloc[:-valid_size]
y_temp_valid          = y_temp_train.iloc[-valid_size:]

y_rain_train_internal = y_rain_train.iloc[:-valid_size]
y_rain_valid          = y_rain_train.iloc[-valid_size:]
```

---

## **4. Treinamento**

Modelos base com:

* 3000‚Äì5000 √°rvores
* `learning_rate` reduzido
* **early stopping**

O uso de early stopping impede overfitting, encerrando o treinamento quando a valida√ß√£o deixa de melhorar, resultando em modelos mais generaliz√°veis.

```python
# === MODELO BASE ‚Äî TEMPERATURA ===

modelo_temp = LGBMRegressor(
    n_estimators=5000,
    learning_rate=0.01,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1
)

modelo_temp.fit(
    X_train_internal,
    y_temp_train_internal,
    eval_set=[(X_valid, y_temp_valid)],
    eval_metric="rmse",
    callbacks=[lgb.early_stopping(stopping_rounds=100)]
)

y_pred_train = modelo_temp.predict(X_train_internal)
y_pred_valid = modelo_temp.predict(X_valid)

mae_tr, rmse_tr = avaliar(y_temp_train_internal, y_pred_train)
mae_va, rmse_va = avaliar(y_temp_valid, y_pred_valid)

print("Treino:", mae_tr, rmse_tr)
print("Valida√ß√£o:", mae_va, rmse_va)

# === MODELO BASE ‚Äî CHUVA (RAIN) ===

modelo_rain = LGBMRegressor(
    n_estimators=5000,
    learning_rate=0.01,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    n_jobs=-1
)

modelo_rain.fit(
    X_train_internal,
    y_rain_train_internal,
    eval_set=[(X_valid, y_rain_valid)],
    eval_metric="rmse",
    callbacks=[lgb.early_stopping(stopping_rounds=100)]
)

y_rain_pred_train  = modelo_rain.predict(X_train_internal)
y_rain_pred_valid  = modelo_rain.predict(X_valid)

mae_tr_rain, rmse_tr_rain = avaliar(y_rain_train_internal, y_rain_pred_train)
mae_va_rain, rmse_va_rain = avaliar(y_rain_valid, y_rain_pred_valid)

print("RAIN ‚Äî Treino:")
print(f"MAE = {mae_tr_rain:.3f}   RMSE = {rmse_tr_rain:.3f}")
print("\nRAIN ‚Äî Valida√ß√£o Interna:")
print(f"MAE = {mae_va_rain:.3f}   RMSE = {rmse_va_rain:.3f}")

```

---

## **5. Valida√ß√£o Cruzada Temporal (TSCV)**

* Implementa√ß√£o de TimeSeriesSplit
* Avalia√ß√£o com 5 folds
* M√©trica principal: RMSE

Essa valida√ß√£o verifica a estabilidade do modelo em v√°rias janelas temporais, simulando diferentes per√≠odos futuros e oferecendo uma avalia√ß√£o mais confi√°vel do desempenho.

```python
# === CROSS-VALIDATION TEMPORAL ‚Äî TEMPERATURA ===

tscv = TimeSeriesSplit(n_splits=5)
rmse_scores = []

print("Executando TSCV...\n")

for fold, (train_idx, test_idx) in tqdm(
    enumerate(tscv.split(X_train), start=1),
    total=5
):
    X_tr, X_te = X_train.iloc[train_idx], X_train.iloc[test_idx]
    y_tr, y_te = y_temp_train.iloc[train_idx], y_temp_train.iloc[test_idx]

    modelo = LGBMRegressor(
        n_estimators=3000,
        learning_rate=0.02,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )

    modelo.fit(
        X_tr, y_tr,
        eval_set=[(X_te, y_te)],
        eval_metric="rmse",
        callbacks=[lgb.early_stopping(stopping_rounds=80)]
    )

    preds = modelo.predict(X_te)
    rmse_scores.append(np.sqrt(mean_squared_error(y_te, preds)))

print("RMSE m√©dio:", np.mean(rmse_scores))
print("Desvio:", np.std(rmse_scores))

# === CROSS-VALIDATION TEMPORAL ‚Äî RAIN ===

tscv_rain = TimeSeriesSplit(n_splits=5)
rmse_scores_rain = []

print("Executando TSCV para RAIN...\n")

for fold, (train_idx, test_idx) in tqdm(
    enumerate(tscv_rain.split(X_train), start=1),
    total=5
):
    X_tr, X_te = X_train.iloc[train_idx], X_train.iloc[test_idx]
    y_tr, y_te = y_rain_train.iloc[train_idx], y_rain_train.iloc[test_idx]

    modelo = LGBMRegressor(
        n_estimators=3000,
        learning_rate=0.02,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        n_jobs=-1
    )

    modelo.fit(
        X_tr, y_tr,
        eval_set=[(X_te, y_te)],
        eval_metric="rmse",
        callbacks=[lgb.early_stopping(stopping_rounds=80)]
    )

    preds = modelo.predict(X_te)
    rmse = np.sqrt(mean_squared_error(y_te, preds))
    rmse_scores_rain.append(rmse)

    tqdm.write(f"Fold {fold}/5 ‚Äî RMSE RAIN: {rmse:.3f}")

print("\n===== RESULTADOS CV - RAIN =====")
print(f"RMSE M√âDIO: {np.mean(rmse_scores_rain):.4f}")
print(f"DESVIO:     {np.std(rmse_scores_rain):.4f}")
```

---

## **6. Otimiza√ß√£o dos Hiperpar√¢metros (Random Search)**

Avalia√ß√£o de combina√ß√µes de:

* `num_leaves`
* `max_depth`
* `learning_rate`
* Regulariza√ß√£o L1/L2
* `feature_fraction`
* `bagging_fraction`
* `min_data_in_leaf`

O Random Search foi utilizado para explorar m√∫ltiplas configura√ß√µes do LightGBM de forma eficiente, acelerando a busca por combina√ß√µes que entregassem o menor erro sem exigir uma busca exaustiva.

```python
# === RANDOM SEARCH ‚Äî TEMPERATURA ===

param_dist = {
    "num_leaves": [31, 63, 127],
    "learning_rate": [0.01, 0.03, 0.05, 0.1],
    "min_data_in_leaf": [20, 40, 60],
    "feature_fraction": [0.7, 0.8, 0.9],
    "bagging_fraction": [0.7, 0.8, 0.9],
    "bagging_freq": [1, 3],
    "max_depth": [-1, 5, 8],
    "lambda_l1": [0, 0.1, 0.3],
    "lambda_l2": [0, 0.1, 0.3],
}

@contextmanager
def suppress_stdout():
    with open(os.devnull, "w") as devnull:
        old = sys.stdout
        sys.stdout = devnull
        yield
        sys.stdout = old

param_list = list(ParameterSampler(param_dist, n_iter=20, random_state=42))

best_score = float("inf")
best_params = None

for params in tqdm(param_list):
    scores = []
    for train_idx, test_idx in TimeSeriesSplit(n_splits=5).split(X_train):
        X_tr, X_te = X_train.iloc[train_idx], X_train.iloc[test_idx]
        y_tr, y_te = y_temp_train.iloc[train_idx], y_temp_train.iloc[test_idx]

        model = LGBMRegressor(**params, random_state=42, n_jobs=-1, verbosity=-1)

        with suppress_stdout():
            model.fit(
                X_tr, y_tr,
                eval_set=[(X_te, y_te)],
                eval_metric="rmse",
                callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False)]
            )

        rmse = np.sqrt(mean_squared_error(y_te, model.predict(X_te)))
        scores.append(rmse)

    mean_rmse = np.mean(scores)

    if mean_rmse < best_score:
        best_score = mean_rmse
        best_params = params

print("Melhores hiperpar√¢metros:", best_params)
print("Melhor RMSE:", best_score)

# === RANDOM SEARCH ‚Äî RAIN ===

param_dist_rain = {
    "num_leaves": [31, 63, 127],
    "learning_rate": [0.01, 0.03, 0.05, 0.1],
    "min_data_in_leaf": [20, 40, 60],
    "feature_fraction": [0.7, 0.8, 0.9],
    "bagging_fraction": [0.7, 0.8, 0.9],
    "bagging_freq": [1, 3],
    "max_depth": [-1, 5, 8],
    "lambda_l1": [0, 0.1, 0.3],
    "lambda_l2": [0, 0.1, 0.3],
}

param_list_rain = list(ParameterSampler(param_dist_rain, n_iter=20, random_state=42))

best_score_rain = float("inf")
best_params_rain = None

print("Iniciando busca de hiperpar√¢metros para RAIN...\n")

for params in tqdm(param_list_rain, desc="Random Search RAIN"):
    fold_scores = []

    for train_idx, test_idx in TimeSeriesSplit(n_splits=5).split(X_train):
        X_tr, X_te = X_train.iloc[train_idx], X_train.iloc[test_idx]
        y_tr, y_te = y_rain_train.iloc[train_idx], y_rain_train.iloc[test_idx]

        model_rain = LGBMRegressor(
            **params,
            random_state=42,
            n_jobs=-1,
            verbosity=-1
        )

        with suppress_stdout():
            model_rain.fit(
                X_tr, y_tr,
                eval_set=[(X_te, y_te)],
                eval_metric="rmse",
                callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False)]
            )

        preds = model_rain.predict(X_te)
        rmse = np.sqrt(mean_squared_error(y_te, preds))
        fold_scores.append(rmse)

    mean_rmse = np.mean(fold_scores)

    if mean_rmse < best_score_rain:
        best_score_rain = mean_rmse
        best_params_rain = params

print("\n===== MELHORES HIPERPAR√ÇMETROS RAIN =====")
print(best_params_rain)
print("Melhor RMSE encontrado:", best_score_rain)
```

---

## **7. Treino Final e Avalia√ß√£o**

Ap√≥s encontrar os melhores hiperpar√¢metros, foi realizado:

* treino final dos modelos
* avalia√ß√£o completa em:

  * treino
  * valida√ß√£o interna
  * teste final

Tamb√©m foram gerados gr√°ficos de:

* s√©rie temporal (real vs previsto)
* dispers√£o (scatter plot)
* distribui√ß√£o dos res√≠duos

Essas visualiza√ß√µes ajudam a verificar padr√µes, desvios sistem√°ticos e confiabilidade das previs√µes.

```python
# === MODELO FINAL ‚Äî TEMPERATURA ===

modelo_temp_final = LGBMRegressor(
    **best_params,
    random_state=42,
    n_jobs=-1
)

modelo_temp_final.fit(
    X_train,
    y_temp_train,
    eval_set=[(X_test, y_temp_test)],
    eval_metric="rmse",
    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False)]
)

y_pred_train_final = modelo_temp_final.predict(X_train)
y_pred_valid_final = modelo_temp_final.predict(X_valid)
y_pred_test_final  = modelo_temp_final.predict(X_test)

print("Treino:", avaliar(y_temp_train, y_pred_train_final))
print("Valida√ß√£o:", avaliar(y_temp_valid, y_pred_valid_final))
print("Teste:", avaliar(y_temp_test, y_pred_test_final))

# === MODELO FINAL ‚Äî CHUVA (RAIN) ===

modelo_rain_final = LGBMRegressor(
    **best_params_rain,
    random_state=42,
    n_jobs=-1
)

modelo_rain_final.fit(
    X_train,
    y_rain_train,
    eval_set=[(X_test, y_rain_test)],
    eval_metric="rmse",
    callbacks=[lgb.early_stopping(stopping_rounds=80, verbose=False)]
)

# Previs√µes finais
y_rain_pred_train_final = modelo_rain_final.predict(X_train)
y_rain_pred_valid_final = modelo_rain_final.predict(X_valid)
y_rain_pred_test_final  = modelo_rain_final.predict(X_test)

# M√©tricas finais
print("\n===== RESULTADOS FINAIS - RAIN =====\n")

print("Treino:")
print("MAE  =", round(mean_absolute_error(y_rain_train, y_rain_pred_train_final), 3))
print("RMSE =", round(np.sqrt(mean_squared_error(y_rain_train, y_rain_pred_train_final)), 3))

print("\nValida√ß√£o Interna:")
print("MAE  =", round(mean_absolute_error(y_rain_valid, y_rain_pred_valid_final), 3))
print("RMSE =", round(np.sqrt(mean_squared_error(y_rain_valid, y_rain_pred_valid_final)), 3))

print("\nTeste Final:")
print("MAE  =", round(mean_absolute_error(y_rain_test, y_rain_pred_test_final), 3))
print("RMSE =", round(np.sqrt(mean_squared_error(y_rain_test, y_rain_pred_test_final)), 3))

```

---

## **8. Gera√ß√£o das Previs√µes Futuras**

Para prever o pr√≥ximo ano hora a hora:

* cria√ß√£o de `time_ref = time - 365 dias`
* reaproveitamento das features correspondentes
* previs√£o utilizando os dois modelos treinados
* p√≥s-processamento:

  * temperatura com 1 casa decimal
  * chuva limitada a valores ‚â• 0

Esse m√©todo mant√©m coer√™ncia temporal, reaproveitando padr√µes hist√≥ricos referentes ao mesmo per√≠odo anual.

```python
# === PREPARO PARA PREVIS√ÉO DO PR√ìXIMO ANO ===

# df_features_scaled ter√°: time + todas as features escaladas
df_features_scaled = pd.concat([df["time"], X_scaled], axis=1)

# Datas futuras
future_times = pd.date_range(
    start=df["time"].max() + pd.Timedelta(hours=1),
    periods=24 * 365,
    freq="H"
)

future_df = pd.DataFrame({"time": future_times})
future_df["time_ref"] = future_df["time"] - pd.Timedelta(days=365)

# Merge com o ano anterior
future_merged = future_df.merge(
    df_features_scaled,
    left_on="time_ref",
    right_on="time",
    how="left",
    suffixes=("_future", "_past")
).drop(columns=["time_past"]).rename(columns={"time_future": "time"})

# === PREVIS√ÉO FINAL ===

X_future = future_merged[feature_cols].fillna(0)

temp_future = np.round(modelo_temp_final.predict(X_future), 1)
rain_future = np.round(np.clip(modelo_rain_final.predict(X_future), 0, None), 1)

df_prev = pd.DataFrame({
    "time": future_merged["time"],
    "temperature": temp_future,
    "rain": rain_future
})

df_prev.head()
```

---

## **9. Exporta√ß√£o Final**

O arquivo:

```
PREVISAO.csv
```

cont√©m:

* `time` (yyyy-MM-ddTHH:mm)
* `temperature`
* `rain`

---

# üìä **Resultados dos Modelos**

## **Temperatura**

* **MAE (Teste):** ~0.39¬∞C
* **RMSE (Teste):** ~0.53¬∞C
* **Erro relativo m√©dio:** ~1.3%

O modelo apresenta bom desempenho para previs√µes hor√°rias, com baixa variabilidade.

---

## **Chuva**

* **MAE (Teste):** ~0.10 mm
* **RMSE (Teste):** ~0.38 mm
* **Desvio nos folds:** ~0.02

A estabilidade entre os folds indica um modelo consistente e generaliz√°vel.

<img width="1286" height="418" alt="{251FF2DA-3A9E-4BF7-BE27-CEDD94A212BE}" src="https://github.com/user-attachments/assets/afcf6543-661a-4edd-af97-677e30ea6f83" />

<img width="1263" height="408" alt="{A5DEA6F2-F893-4459-BF3F-D0A83458BFFE}" src="https://github.com/user-attachments/assets/11f3ad42-fc93-4ff7-8029-02784ce24774" />

Esses resultados atendem plenamente ao desafio, oferecendo previs√µes coesas e confi√°veis.
